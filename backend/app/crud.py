import json
import logging
from typing import Optional

from sqlalchemy.orm import Session

from . import models, schemas, persona_engine

logger = logging.getLogger(__name__)

def get_personas(db: Session, skip: int = 0, limit: int = 100):
    """Retrieve all personas from the database."""
    return db.query(models.Persona).offset(skip).limit(limit).all()

def search_personas(db: Session, filters: schemas.PersonaSearchFilters):
    """Search personas based on structured filters."""
    print(f"ðŸ” Searching with filters: {filters.dict()}")
    query = db.query(models.Persona)
    
    if filters.age_min is not None:
        query = query.filter(models.Persona.age >= filters.age_min)
    if filters.age_max is not None:
        query = query.filter(models.Persona.age <= filters.age_max)
    if filters.gender:
        query = query.filter(models.Persona.gender.ilike(filters.gender))
    if filters.condition:
        query = query.filter(models.Persona.condition.ilike(f"%{filters.condition}%"))
    if filters.location:
        query = query.filter(models.Persona.location.ilike(f"%{filters.location}%"))
    if filters.persona_type:
        query = query.filter(models.Persona.persona_type.ilike(filters.persona_type))
    if filters.brand_id is not None:
        query = query.filter(models.Persona.brand_id == filters.brand_id)
        
    return query.limit(filters.limit).all()

def create_persona(db: Session, persona_data: schemas.PersonaCreate, persona_json: str):
    """
    Create a new persona entry in the database.
    
    Args:
        db: The database session.
        persona_data: The input data used for generation (age, gender, etc.).
        persona_json: The full JSON string generated by the LLM.
    """
    # The persona_json string might contain the name, let's parse it to be safe
    generated_data = json.loads(persona_json)
    
    db_persona = models.Persona(
        name=generated_data.get("name", "Unnamed Persona"),
        age=persona_data.age,
        gender=persona_data.gender,
        condition=persona_data.condition,
        location=persona_data.location,
        brand_id=persona_data.brand_id,
        full_persona_json=persona_json
    )
    try:
        db.add(db_persona)
        db.commit()
        db.refresh(db_persona)
        return db_persona
    except Exception:
        db.rollback()
        raise

def get_persona(db: Session, persona_id: int):
    return db.query(models.Persona).filter(models.Persona.id == persona_id).first()

def get_personas_by_brand(db: Session, brand_id: int, skip: int = 0, limit: int = 100):
    """Get all personas belonging to a specific brand."""
    return db.query(models.Persona).filter(
        models.Persona.brand_id == brand_id
    ).offset(skip).limit(limit).all()

def get_personas_count_by_brand(db: Session, brand_id: int) -> int:
    """Get the count of personas for a specific brand."""
    return db.query(models.Persona).filter(
        models.Persona.brand_id == brand_id
    ).count()

def update_persona(db: Session, persona_id: int, persona: schemas.PersonaUpdate):
    db_persona = db.query(models.Persona).filter(models.Persona.id == persona_id).first()
    if db_persona:
        update_data = persona.dict(exclude_unset=True)
        full_payload = update_data.get("full_persona_json")
        if isinstance(full_payload, dict):
            update_data["full_persona_json"] = json.dumps(full_payload)
        for key, value in update_data.items():
            setattr(db_persona, key, value)
        db.commit()
        db.refresh(db_persona)
    return db_persona

def delete_persona(db: Session, persona_id: int):
    db_persona = db.query(models.Persona).filter(models.Persona.id == persona_id).first()
    if db_persona:
        db.delete(db_persona)
        db.commit()
        return True
    return False

def create_simulation(db: Session, simulation: schemas.SimulationCreate):
    db_simulation = models.Simulation(**simulation.dict())
    db.add(db_simulation)
    db.commit()
    db.refresh(db_simulation)
    return db_simulation

def get_simulation(db: Session, simulation_id: int):
    return db.query(models.Simulation).filter(models.Simulation.id == simulation_id).first()

def get_simulations(db: Session, skip: int = 0, limit: int = 100):
    return db.query(models.Simulation).offset(skip).limit(limit).all()

def update_simulation_results(db: Session, simulation_id: int, results: dict, response_rate: float, insights: str):
    db_simulation = db.query(models.Simulation).filter(models.Simulation.id == simulation_id).first()
    if db_simulation:
        db_simulation.results = results
        db_simulation.response_rate = response_rate
        db_simulation.insights = insights
        db.commit()
        db.refresh(db_simulation)
    return db_simulation

def create_cohort_simulation(db: Session, persona_ids: list, stimulus_text: str, results: dict, insights: list):
    """Create simulation records for cohort analysis"""
    # Calculate average response rate from results
    response_rates = []
    for response in results.get('individual_responses', []):
        # Calculate a response rate based on purchase intent (normalized to 0-100)
        if 'intent_to_action' in response.get('responses', {}):
            response_rates.append(response['responses']['intent_to_action'] * 10)  # Convert 1-10 to 10-100
    
    avg_response_rate = sum(response_rates) / len(response_rates) if response_rates else 0
    
    # Store simulation for each persona
    for persona_id in persona_ids:
        db_simulation = models.Simulation(
            persona_id=persona_id,
            scenario=stimulus_text,
            parameters={"metrics": results.get('metrics_analyzed', [])},
            results=results,
            response_rate=avg_response_rate,
            insights=json.dumps(insights)
        )
        db.add(db_simulation)
    
    db.commit()
    return avg_response_rate

def get_simulation_stats(db: Session):
    """Get statistics about simulations"""
    from sqlalchemy import func
    from datetime import datetime, timedelta
    
    # Count total simulations
    total_simulations = db.query(models.Simulation).count()
    
    # Count simulations this month
    start_of_month = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    monthly_simulations = db.query(models.Simulation).filter(
        models.Simulation.created_at >= start_of_month
    ).count()
    
    # Calculate average response rate
    avg_response_rate = db.query(func.avg(models.Simulation.response_rate)).scalar()
    
    # Count total insights (each simulation can have multiple insights)
    total_insights = 0
    simulations = db.query(models.Simulation).all()
    for sim in simulations:
        if sim.insights:
            try:
                insights_list = json.loads(sim.insights)
                total_insights += len(insights_list)
            except:
                pass
    
    return {
        "total_simulations": total_simulations,
        "monthly_simulations": monthly_simulations,
        "avg_response_rate": avg_response_rate or 0,
        "total_insights": total_insights
    }

# CRUD for Saved Simulations
def create_saved_simulation(db: Session, simulation_data: schemas.SavedSimulationCreate):
    db_saved_simulation = models.SavedSimulation(**simulation_data.dict())
    db.add(db_saved_simulation)
    db.commit()
    db.refresh(db_saved_simulation)
    return db_saved_simulation

def get_saved_simulation(db: Session, simulation_id: int):
    return db.query(models.SavedSimulation).filter(models.SavedSimulation.id == simulation_id).first()

def get_saved_simulations(db: Session, skip: int = 0, limit: int = 100):
    return db.query(models.SavedSimulation).order_by(models.SavedSimulation.created_at.desc()).offset(skip).limit(limit).all()

def delete_saved_simulation(db: Session, simulation_id: int):
    db_saved_simulation = db.query(models.SavedSimulation).filter(models.SavedSimulation.id == simulation_id).first()
    if db_saved_simulation:
        db.delete(db_saved_simulation)
        db.commit()
        return True
    return False

# CRUD for Brand Library
def create_brand(db: Session, brand: schemas.BrandCreate):
    db_brand = models.Brand(name=brand.name)
    db.add(db_brand)
    db.commit()
    db.refresh(db_brand)
    return db_brand

def get_brands(db: Session, skip: int = 0, limit: int = 100):
    return db.query(models.Brand).offset(skip).limit(limit).all()

def create_brand_document(db: Session, document: schemas.BrandDocumentCreate):
    db_document = models.BrandDocument(**document.dict())
    db.add(db_document)
    db.commit()
    db.refresh(db_document)
    return db_document


def _delete_vector_store(vector_store_id: Optional[str]) -> None:
    """Best-effort cleanup of remote vector stores.

    The operation is intentionally idempotent and should never raise, to avoid
    blocking local state changes when the remote store is already removed or
    unavailable.
    """

    if not vector_store_id:
        return

    client = persona_engine.get_openai_client()
    vector_api = getattr(client, "vector_stores", None) if client else None

    if vector_api is None:
        logger.info("Vector store cleanup skipped (no client/vector API available).")
        return

    try:
        vector_api.delete(vector_store_id)
        logger.info("Deleted vector store %s during brand document cleanup.", vector_store_id)
    except Exception as exc:  # noqa: BLE001 - logging best-effort cleanup
        logger.warning("Vector store cleanup failed for %s: %s", vector_store_id, exc)


def upsert_brand_document(db: Session, document: schemas.BrandDocumentCreate):
    """Create or replace a brand document while cleaning up stale vectors.

    If a document with the same brand and filename exists, it will be updated
    with the new payload. When a replacement includes a new vector store ID,
    the previous vector store is removed on a best-effort basis.
    """

    existing = db.query(models.BrandDocument).filter(
        models.BrandDocument.brand_id == document.brand_id,
        models.BrandDocument.filename == document.filename,
    ).first()

    if existing:
        previous_vector_store = existing.vector_store_id
        for key, value in document.dict().items():
            setattr(existing, key, value)

        db.commit()
        db.refresh(existing)

        if previous_vector_store and previous_vector_store != existing.vector_store_id:
            _delete_vector_store(previous_vector_store)

        return existing

    return create_brand_document(db, document)


def delete_brand_document(db: Session, document_id: int, *, brand_id: Optional[int] = None) -> bool:
    query = db.query(models.BrandDocument).filter(models.BrandDocument.id == document_id)
    if brand_id is not None:
        query = query.filter(models.BrandDocument.brand_id == brand_id)

    db_document = query.first()
    if db_document:
        vector_store_id = db_document.vector_store_id
        db.delete(db_document)
        db.commit()
        _delete_vector_store(vector_store_id)
        return True

    return False

def get_brand_documents(db: Session, brand_id: int):
    return db.query(models.BrandDocument).filter(models.BrandDocument.brand_id == brand_id).all()
